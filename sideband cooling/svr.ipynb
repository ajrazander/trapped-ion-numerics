{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML for optimal sideband cooling\n",
    "There are two optimization in multiorder sideband cooling: pulse schedule (time of each laser pulse) and what order RSB is applied.\n",
    "\n",
    "1) Optimal sideband cooling pulse times can take a long time to compute, but funcitonally they look quite smooth and only rely on a few easily measured/calculated parameters. Could machine learning bridge the gap instead of a direct minimzation?\n",
    "\n",
    "2) Determining when to apply what order RSB is an exponentially hard problem, yet it seems to follow a \"block\" ordering (highest orders first; first-order last). Can ML be used to estimate the optimal sequence of RSB orders instead of brute force optimizing over an exponential problem?\n",
    "\n",
    "What ML models should we use? Neural Network would work, but since we want to predict a varying number of pulse timings, the number of output nodes would need to vary as well. That doesn't sound like a good fit.\n",
    "\n",
    "SVM is a rising trend. We could use the regression version SVR to predict pulse times of a fixed strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support Vector Regression\n",
    "# For improved computational speed\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn import svm, preprocessing\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "from sideband_cooling import simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict optimal pulse time (FIXED METHOD)\n",
    "# eta, pi/omega0, initial nbar, and number of pulses\n",
    "\n",
    "# %% Generate dataset\n",
    "N_rand = 200\n",
    "\n",
    "omegas = 2*np.pi * np.linspace(1/(2 * 5e-6), 1/(2 * 20e-6), 50)\n",
    "omega_rands = np.random.choice(omegas, N_rand)\n",
    "\n",
    "# Assume eta and initial nbar are computable from confining harmonic frequency omega_z\n",
    "omega_zs = 2*np.pi * np.linspace(0.5, 3, 50) * 1e6\n",
    "omega_z_rands = np.random.choice(omega_zs, N_rand)\n",
    "\n",
    "lam = 355e-9\n",
    "hbar = 1.05457e-34\n",
    "m = 170.936 * 1.6605e-27\n",
    "eta_rands = np.sqrt(2) * 2*np.pi/lam * np.sqrt(hbar/2/m/omega_z_rands)\n",
    "\n",
    "initial_nbar_rands = 19.6e6/2/(omega_z_rands/2/np.pi)\n",
    "\n",
    "N_pulses_rands = np.random.choice(np.arange(5, 50), N_rand)\n",
    "\n",
    "strategy = 'fixed'\n",
    "cooled_nbars = []\n",
    "pulse_schedules = []\n",
    "for omega_z, initial_nbar, omega, N_pulses in tqdm(zip(omega_z_rands, initial_nbar_rands, omega_rands, N_pulses_rands), total=len(omega_z_rands)):\n",
    "    sim = simulation.SidebandCooling(omega_z, initial_nbar, omega)\n",
    "    cooled_nbar, pulse_schedule, cooling_time, cooled_dist = sim.cool(strategy, N_pulses, 1)\n",
    "    cooled_nbars.append(cooled_nbar)\n",
    "    pulse_schedules.append(pulse_schedule[0])\n",
    "    sim.reset_current_dist()\n",
    "\n",
    "# Simulate and save data\n",
    "pi_times = np.pi / omega_rands\n",
    "dataX = np.column_stack((eta_rands, pi_times, initial_nbar_rands, N_pulses_rands))\n",
    "dataY = np.array(pulse_schedules)\n",
    "\n",
    "# Save data into files\n",
    "with open('data/dataX_fixed_nbar.npy', 'wb') as f:\n",
    "    np.save(f, dataX)\n",
    "with open('data/dataY_fixed_nbar.npy', 'wb') as f:\n",
    "    np.save(f, dataY)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Load and preprocess data\n",
    "\n",
    "# load data\n",
    "with open('data/dataX_fixed_nbar.npy', 'rb') as f:\n",
    "    dataX = np.load(f)\n",
    "with open('data/dataY_fixed_nbar.npy', 'rb') as f:\n",
    "    dataY = np.load(f)\n",
    "    \n",
    "# Preprocess data\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataX, dataY, test_size=0.33, random_state=42)\n",
    "\n",
    "scalerX = preprocessing.StandardScaler().fit(X_train)\n",
    "scalery = preprocessing.StandardScaler().fit(y_train.reshape(-1,1))\n",
    "X_train = scalerX.transform(X_train)\n",
    "y_train = (scalery.transform(y_train.reshape(-1,1))).reshape(-1,)\n",
    "X_test = scalerX.transform(X_test)\n",
    "y_test = (scalery.transform(y_test.reshape(-1,1))).reshape(-1,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Use Cross-validation to tune svr hyperparameters\n",
    "svr = svm.SVR()\n",
    "\n",
    "param_grid = [{'C': [1, 10, 100, 1000, 5000, 10000], 'gamma': [0.005, 0.01, 0.02, 0.03, 0.04, 0.05, 0.06], 'kernel': ['rbf']}]\n",
    "svr_grid = GridSearchCV(svr, param_grid, scoring='r2')\n",
    "svr_grid.fit(X_train, y_train)\n",
    "\n",
    "means = svr_grid.cv_results_['mean_test_score']\n",
    "stds = svr_grid.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, svr_grid.cv_results_['params']):\n",
    "    print(\"%0.4f (+/-%0.04f) for %r\"\n",
    "          % (mean, std * 2, params))\n",
    "print(\"Best parameters set found on development set:\\n\")\n",
    "print(svr_grid.best_params_,\"\\n\")\n",
    "print(\"Grid scores on development set:\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Save otpimal hyperparameters and train\n",
    "\n",
    "gamma_opt = svr_grid.best_params_['gamma']\n",
    "C_opt = svr_grid.best_params_['C']\n",
    "\n",
    "# train SVR on training data\n",
    "svr = svm.SVR(C=C_opt, gamma=gamma_opt)\n",
    "svr.fit(X_train, y_train)\n",
    "\n",
    "# compute predictions on test data\n",
    "preds = svr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Analyze model\n",
    "\n",
    "# convert y's back to time\n",
    "preds_times = scalery.inverse_transform(preds)\n",
    "y_test_times = scalery.inverse_transform(y_test)\n",
    "\n",
    "plt.figure(figsize=(7,6.5))\n",
    "plt.scatter(y_test_times, preds_times)\n",
    "plt.plot(preds_times,preds_times, '-r')\n",
    "plt.xlabel('exact')\n",
    "plt.ylabel('prediction')\n",
    "plt.title('SVR pred vs actual')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "rel_errors = np.abs((preds_times - y_test_times)/y_test_times)\n",
    "\n",
    "plt.figure(figsize=(7,3))\n",
    "plt.scatter(y_test_times, rel_errors)\n",
    "plt.title('Relative error between exact and prediction')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "print('root mean square', np.sqrt(np.mean((y_test_times - preds_times)**2)))\n",
    "print('average relative error', np.mean(rel_errors), '+/-', np.std(rel_errors))\n",
    "correlation_matrix = np.corrcoef(y_test_times, preds_times)\n",
    "correlation_xy = correlation_matrix[0,1]\n",
    "r_squared = correlation_xy**2\n",
    "print('r squared', r_squared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
